{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mister Car Wash - ML Model Training\n",
    "\n",
    "This notebook trains three machine learning models for the Mister Car Wash Intelligence Agent:\n",
    "1. **CHURN_RISK_PREDICTOR**: Predicts if a member will cancel.\n",
    "2. **EQUIPMENT_FAILURE_PREDICTOR**: Predicts if equipment needs maintenance.\n",
    "3. **UPSELL_PROPENSITY_SCORER**: Predicts if a member is likely to upgrade.\n",
    "\n",
    "**Single Source of Truth**: All models train on `V_..._FEATURES` views in `ANALYTICS` schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
    "from snowflake.ml.modeling.linear_model import LogisticRegression\n",
    "from snowflake.ml.modeling.preprocessing import OneHotEncoder, StandardScaler\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.ml.modeling.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current session\n",
    "session = Session.builder.getOrCreate()\n",
    "\n",
    "# Set context\n",
    "session.use_database(\"MISTER_CAR_WASH_INTELLIGENCE\")\n",
    "session.use_schema(\"ANALYTICS\")\n",
    "session.use_warehouse(\"MISTER_CAR_WASH_WH\")\n",
    "\n",
    "print(\"✅ Session configured\")\n",
    "print(f\"Database: {session.get_current_database()}\")\n",
    "print(f\"Schema: {session.get_current_schema()}\")\n",
    "print(f\"Warehouse: {session.get_current_warehouse()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model Registry\n",
    "registry = Registry(\n",
    "    session=session,\n",
    "    database_name=\"MISTER_CAR_WASH_INTELLIGENCE\",\n",
    "    schema_name=\"ANALYTICS\"\n",
    ")\n",
    "\n",
    "print(\"✅ Model Registry initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Churn Risk Predictor\n",
    "\n",
    "**Objective**: Predict likelihood of member churn (cancellation).\n",
    "**Features**: LTV_SCORE, TENURE_DAYS, DAYS_SINCE_LAST_WASH, TOTAL_WASHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load churn feature data\n",
    "churn_df = session.table(\"MISTER_CAR_WASH_INTELLIGENCE.ANALYTICS.V_CHURN_RISK_FEATURES\")\n",
    "\n",
    "print(f\"✅ Loaded {churn_df.count()} records for churn prediction\")\n",
    "churn_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_churn, test_churn = churn_df.random_split([0.8, 0.2], seed=42)\n",
    "\n",
    "# Drop ID columns not needed for training\n",
    "train_churn = train_churn.drop(\"MEMBER_ID\", \"STATUS\")\n",
    "test_churn = test_churn.drop(\"MEMBER_ID\", \"STATUS\")\n",
    "\n",
    "print(f\"Training set: {train_churn.count()} records\")\n",
    "print(f\"Test set: {test_churn.count()} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for Churn Prediction\n",
    "churn_pipeline = Pipeline([\n",
    "    (\"Scaler\", StandardScaler(\n",
    "        input_cols=[\"LTV_SCORE\", \"TENURE_DAYS\", \"DAYS_SINCE_LAST_WASH\", \"TOTAL_WASHES\"],\n",
    "        output_cols=[\"LTV_SCALED\", \"TENURE_SCALED\", \"RECENCY_SCALED\", \"FREQ_SCALED\"]\n",
    "    )),\n",
    "    (\"Classifier\", LogisticRegression(\n",
    "        label_cols=[\"IS_CHURNED\"],\n",
    "        output_cols=[\"PREDICTED_CHURN\"],\n",
    "        max_iter=100\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"✅ Churn prediction pipeline created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"Training churn prediction model...\")\n",
    "churn_pipeline.fit(train_churn)\n",
    "print(\"✅ Churn prediction model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "test_predictions = churn_pipeline.predict(test_churn)\n",
    "test_results = test_predictions.select(\"IS_CHURNED\", \"PREDICTED_CHURN\").to_pandas()\n",
    "\n",
    "accuracy = accuracy_score(test_results['IS_CHURNED'], test_results['PREDICTED_CHURN'])\n",
    "print(f\"Test Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model\n",
    "sample_data = train_churn.drop(\"IS_CHURNED\").limit(100)\n",
    "\n",
    "registry.log_model(\n",
    "    model=churn_pipeline,\n",
    "    model_name=\"CHURN_RISK_PREDICTOR\",\n",
    "    target_platforms=['WAREHOUSE'],\n",
    "    sample_input_data=sample_data,\n",
    "    comment=\"Predicts member churn risk\"\n",
    ")\n",
    "\n",
    "print(\"✅ CHURN_RISK_PREDICTOR registered in Model Registry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Equipment Failure Predictor\n",
    "\n",
    "**Objective**: Predict equipment failure risk.\n",
    "**Features**: DAYS_SINCE_LAST_SERVICE, LAST_SERVICE_COST, SEVERITY_SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load equipment feature data\n",
    "equip_df = session.table(\"MISTER_CAR_WASH_INTELLIGENCE.ANALYTICS.V_MAINTENANCE_RISK_FEATURES\")\n",
    "\n",
    "print(f\"✅ Loaded {equip_df.count()} records for equipment prediction\")\n",
    "equip_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_equip, test_equip = equip_df.random_split([0.8, 0.2], seed=42)\n",
    "\n",
    "# Drop ID columns\n",
    "train_equip = train_equip.drop(\"MAINTENANCE_ID\", \"EQUIPMENT_TYPE\")\n",
    "test_equip = test_equip.drop(\"MAINTENANCE_ID\", \"EQUIPMENT_TYPE\")\n",
    "\n",
    "print(f\"Training set: {train_equip.count()} records\")\n",
    "print(f\"Test set: {test_equip.count()} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for Equipment Failure\n",
    "equip_pipeline = Pipeline([\n",
    "    (\"Scaler\", StandardScaler(\n",
    "        input_cols=[\"DAYS_SINCE_LAST_SERVICE\", \"LAST_SERVICE_COST\", \"SEVERITY_SCORE\"],\n",
    "        output_cols=[\"DAYS_SCALED\", \"COST_SCALED\", \"SEVERITY_SCALED\"]\n",
    "    )),\n",
    "    (\"Classifier\", RandomForestClassifier(\n",
    "        label_cols=[\"FAILURE_RISK_LABEL\"],\n",
    "        output_cols=[\"PREDICTED_FAILURE\"],\n",
    "        n_estimators=10,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"✅ Equipment failure pipeline created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"Training equipment failure model...\")\n",
    "equip_pipeline.fit(train_equip)\n",
    "print(\"✅ Equipment failure model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "test_predictions = equip_pipeline.predict(test_equip)\n",
    "test_results = test_predictions.select(\"FAILURE_RISK_LABEL\", \"PREDICTED_FAILURE\").to_pandas()\n",
    "\n",
    "accuracy = accuracy_score(test_results['FAILURE_RISK_LABEL'], test_results['PREDICTED_FAILURE'])\n",
    "print(f\"Test Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model\n",
    "sample_data = train_equip.drop(\"FAILURE_RISK_LABEL\").limit(100)\n",
    "\n",
    "registry.log_model(\n",
    "    model=equip_pipeline,\n",
    "    model_name=\"EQUIPMENT_FAILURE_PREDICTOR\",\n",
    "    target_platforms=['WAREHOUSE'],\n",
    "    sample_input_data=sample_data,\n",
    "    comment=\"Predicts equipment failure risk\"\n",
    ")\n",
    "\n",
    "print(\"✅ EQUIPMENT_FAILURE_PREDICTOR registered in Model Registry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Upsell Propensity Scorer\n",
    "\n",
    "**Objective**: Predict likelihood of membership upgrade.\n",
    "**Features**: LTV_SCORE, VISIT_COUNT, AVG_RATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load upsell feature data\n",
    "upsell_df = session.table(\"MISTER_CAR_WASH_INTELLIGENCE.ANALYTICS.V_UPSELL_FEATURES\")\n",
    "\n",
    "print(f\"✅ Loaded {upsell_df.count()} records for upsell prediction\")\n",
    "upsell_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_upsell, test_upsell = upsell_df.random_split([0.8, 0.2], seed=42)\n",
    "\n",
    "# Drop ID columns\n",
    "train_upsell = train_upsell.drop(\"MEMBER_ID\", \"MEMBERSHIP_TIER\")\n",
    "test_upsell = test_upsell.drop(\"MEMBER_ID\", \"MEMBERSHIP_TIER\")\n",
    "\n",
    "print(f\"Training set: {train_upsell.count()} records\")\n",
    "print(f\"Test set: {test_upsell.count()} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for Upsell Propensity\n",
    "upsell_pipeline = Pipeline([\n",
    "    (\"Scaler\", StandardScaler(\n",
    "        input_cols=[\"LTV_SCORE\", \"VISIT_COUNT\", \"AVG_RATING\"],\n",
    "        output_cols=[\"LTV_SCALED\", \"VISITS_SCALED\", \"RATING_SCALED\"]\n",
    "    )),\n",
    "    (\"Classifier\", LogisticRegression(\n",
    "        label_cols=[\"UPSELL_LABEL\"],\n",
    "        output_cols=[\"PREDICTED_UPSELL\"],\n",
    "        max_iter=100\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"✅ Upsell pipeline created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"Training upsell model...\")\n",
    "upsell_pipeline.fit(train_upsell)\n",
    "print(\"✅ Upsell model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "test_predictions = upsell_pipeline.predict(test_upsell)\n",
    "test_results = test_predictions.select(\"UPSELL_LABEL\", \"PREDICTED_UPSELL\").to_pandas()\n",
    "\n",
    "accuracy = accuracy_score(test_results['UPSELL_LABEL'], test_results['PREDICTED_UPSELL'])\n",
    "print(f\"Test Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model\n",
    "sample_data = train_upsell.drop(\"UPSELL_LABEL\").limit(100)\n",
    "\n",
    "registry.log_model(\n",
    "    model=upsell_pipeline,\n",
    "    model_name=\"UPSELL_PROPENSITY_SCORER\",\n",
    "    target_platforms=['WAREHOUSE'],\n",
    "    sample_input_data=sample_data,\n",
    "    comment=\"Predicts upsell propensity\"\n",
    ")\n",
    "\n",
    "print(\"✅ UPSELL_PROPENSITY_SCORER registered in Model Registry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all registered models\n",
    "models = session.sql(\"SHOW MODELS IN SCHEMA ANALYTICS\").collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REGISTERED MODELS\")\n",
    "print(\"=\"*80)\n",
    "for model in models:\n",
    "    print(f\"✅ {model['name']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
